import torch
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, random_split, SubsetRandomSampler, ConcatDataset
import numpy as np
import torch
import timm
import torchsummary
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
from sklearn.metrics import confusion_matrix, classification_report, precision_score,
recall_score,
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os
train_transform_augmented = transforms.Compose([
transforms.Resize((224, 224)),
transforms.RandomHorizontalFlip(),
transforms.RandomRotation(10),
transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
transforms.ToTensor(),
transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
train_transform_no_augmentation = transforms.Compose([
transforms.Resize((224, 224)),
transforms.ToTensor(),
transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
base_dir = '/content/HumanActionRecognition/dataset'
full_dataset = ImageFolder(root=base_dir, transform=train_transform_no_augmentation)
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])
target_samples_per_class =2500
class_indices = {class_idx: [] for class_idx in range(len(full_dataset.classes))}
for idx, (_, label_idx) in enumerate(full_dataset.samples):
class_indices[label_idx].append(idx)
class_counts = np.array([len(class_indices[i]) for i in range(len(full_dataset.classes))])
oversample_factors = np.maximum(0, (target_samples_per_class - class_counts) //
class_counts)
oversample_factors = np.floor(oversample_factors).astype(int)
augmented_datasets = []
for class_idx, factor in enumerate(oversample_factors):
if factor > 0:
class_subset = SubsetRandomSampler(class_indices[class_idx])
augmented_dataset = ImageFolder(root=base_dir, transform=train_transform_augmented)
augmented_datasets.append(augmented_dataset)
datasets_to_combine = [train_dataset.dataset] + augmented_datasets
combined_dataset = ConcatDataset(datasets_to_combine)
batch_size = 16
train_loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True)
valid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
class_names = full_dataset.classes
print("\nNumber of classes:", len(class_names))
print("Class names:")
for name in class_names:
print(name)
Number of classes: 15
Class names:
calling
clapping
cycling
dancing
drinking
eating
fighting
hugging
laughing
listening_to_music
running
sitting
sleeping
texting
using_laptop
import matplotlib.pyplot as plt
import numpy as np
def visualize_samples_per_class(dataset, class_names, num_samples=3):
"""
Function to visualize random sample images for each class.
"""
fig, axes = plt.subplots(len(class_names), num_samples, figsize=(num_samples * 3,
len(class_names) * 3))
for class_idx, class_name in enumerate(class_names):
class_indices = [i for i, (_, label) in enumerate(dataset.samples) if label == class_idx]
random_samples = np.random.choice(class_indices, num_samples, replace=False)
for i, sample_idx in enumerate(random_samples):
image, label = dataset[sample_idx]
image = image.permute(1, 2, 0).numpy()
image = np.clip(image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456,
0.406]), 0, 1)
axes[class_idx, i].imshow(image)
axes[class_idx, i].axis("off")
if i == 0:
axes[class_idx, i].set_title(f'{class_name}', fontsize=14)
plt.tight_layout()
plt.show()
visualize_samples_per_class(full_dataset, class_names)
def visualize_class_distribution(dataset, class_names):
"""
Function to visualize the class distribution in the dataset.
"""
class_counts = np.zeros(len(class_names))
for _, label in dataset.samples:
class_counts[label] += 1
plt.figure(figsize=(10, 5))
plt.bar(class_names, class_counts, color='skyblue')
plt.xticks(rotation=90)
plt.xlabel('Class')
plt.ylabel('Number of Images')
plt.title('Class Distribution in Dataset')
plt.show()
visualize_class_distribution(full_dataset, class_names)
from PIL import Image
def plot_image_size_distribution(dataset):
"""Plot the distribution of image sizes (width, height)."""
widths = []
heights = []
for img_path, _ in dataset.samples:
img = Image.open(img_path)
width, height = img.size
widths.append(width)
heights.append(height)
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.hist(widths, bins=20, color='skyblue')
plt.title("Distribution of Image Widths")
plt.xlabel("Width")
plt.ylabel("Frequency")
plt.subplot(1, 2, 2)
plt.hist(heights, bins=20, color='lightcoral')
plt.title("Distribution of Image Heights")
plt.xlabel("Height")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()
plot_image_size_distribution(full_dataset)
def plot_aspect_ratio_distribution(dataset):
"""Plot the distribution of aspect ratios (width/height)"""
aspect_ratios = []
for img_path, _ in dataset.samples:
img = Image.open(img_path)
width, height = img.size
aspect_ratio = width / height
aspect_ratios.append(aspect_ratio)
plt.figure(figsize=(7, 5))
plt.hist(aspect_ratios, bins=20, color='lightgreen')
plt.title("Aspect Ratio Distribution")
plt.xlabel("Aspect Ratio (Width / Height)")
plt.ylabel("Frequency")
plt.show()
plot_aspect_ratio_distribution(full_dataset)
def plot_class_distribution_pie_chart(dataset, class_names):
"""Plot a pie chart to visualize class distribution."""
class_counts = np.zeros(len(class_names))
for _, label in dataset.samples:
class_counts[label] += 1
plt.figure(figsize=(8, 8))
plt.pie(class_counts, labels=class_names, autopct='%1.1f%%',
colors=plt.cm.Paired.colors, startangle=90)
plt.axis('equal')
plt.title('Class Distribution')
plt.show()
plot_class_distribution_pie_chart(full_dataset, class_names)
def plot_image_size_vs_aspect_ratio(dataset):
"""Plot a scatter plot of image sizes (width x height) vs aspect ratios."""
widths = []
heights = []
aspect_ratios = []
for img_path, _ in dataset.samples:
img = Image.open(img_path)
width, height = img.size
aspect_ratios.append(width / height)
widths.append(width)
heights.append(height)
plt.figure(figsize=(8, 6))
plt.scatter(widths, aspect_ratios, color='teal', alpha=0.5)
plt.xlabel('Image Width')
plt.ylabel('Aspect Ratio (Width / Height)')
plt.title('Image Size vs Aspect Ratio')
plt.show()
# Plot image size vs aspect ratio
plot_image_size_vs_aspect_ratio(full_dataset)
